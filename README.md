# Random Forest with and without SMOTE - Comparative Analysis

This repository contains two Jupyter Notebooks demonstrating how SMOTE (Synthetic Minority Over-sampling Technique) impacts the performance of a Random Forest classifier on an imbalanced dataset.

## üîç Objective

To compare the classification performance of:
- **Random Forest without any balancing technique**
- **Random Forest with SMOTE applied to oversample the minority class**

## üìÇ Contents

| File                                  | Description                          |
|---------------------------------------|--------------------------------------|
| `Randomforest_Newdataset_nosmote.ipynb` | Random Forest classification **without SMOTE** |
| `FOREST_SMOTE.ipynb`                   | Random Forest classification **with SMOTE**    |

## üìà Evaluation Metrics
Each notebook evaluates the model using:
- Accuracy
- Confusion Matrix
- Classification Report (Precision, Recall, F1-score)
- ROC-AUC Score (if included)

## ‚öôÔ∏è Libraries Used
- `scikit-learn`
- `imblearn`
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`

## üìù Conclusion
This project helps in understanding the effect of synthetic oversampling techniques like SMOTE in improving the performance of machine learning models on imbalanced datasets.

---

Feel free to clone, run, or extend this work for academic, research, or educational purposes.


## üìÅ Dataset
- [Download Excel Dataset (Google Drive)](https://drive.google.com/drive/folders/1zEG2gec5AwLFsyr7g6c864RzVSs6_ftk?usp=sharing)

